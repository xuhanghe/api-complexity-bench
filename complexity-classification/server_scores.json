{
  "meta": {
    "generated_at": "2025-09-28T03:26:04.897908Z",
    "servers_file": "/home/xuhang/complexity-classification/servers_parsed.json",
    "tools_file": "/home/xuhang/complexity-classification/tools_parsed.json",
    "invalid_tools_skipped": 122,
    "skipped_servers_count": 61
  },
  "server_scores": [
    {
      "server_id": "@gomarble-ai/facebook-ads-mcp-server",
      "server_name": "Facebook Ads Server",
      "factor": 87,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 9.095238095238095,
      "mu_n": 4.857142857142857,
      "mu_d": 791.0,
      "n_tools": 21,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 21,
      "tools_count_actual": 21,
      "tools_count_valid": 21,
      "tools_mismatch": false
    },
    {
      "server_id": "@alphago2580/naramarketmcp",
      "server_name": "NaraMarketMCP",
      "factor": 85,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 7.592592592592593,
      "mu_n": 4.481481481481482,
      "mu_d": 201.8148148148148,
      "n_tools": 27,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 27,
      "tools_count_actual": 27,
      "tools_count_valid": 27,
      "tools_mismatch": false
    },
    {
      "server_id": "brave",
      "server_name": "Brave Search",
      "factor": 79,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 9.833333333333334,
      "mu_n": 4.166666666666667,
      "mu_d": 142.16666666666666,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@jcwleo/ccxt-mcp-server",
      "server_name": "CCXT Cryptocurrency Exchange Server",
      "factor": 78,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 7.473684210526316,
      "mu_n": 3.9473684210526314,
      "mu_d": 82.94736842105263,
      "n_tools": 19,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 19,
      "tools_count_actual": 19,
      "tools_count_valid": 19,
      "tools_mismatch": false
    },
    {
      "server_id": "@chirag127/clear-thought-mcp-server",
      "server_name": "Clear Thought Server",
      "factor": 77,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 9.818181818181818,
      "mu_n": 3.4545454545454546,
      "mu_d": 71.54545454545455,
      "n_tools": 11,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 11,
      "tools_count_actual": 11,
      "tools_count_valid": 11,
      "tools_mismatch": false
    },
    {
      "server_id": "@ThinkFar/clear-thought-mcp",
      "server_name": "Clear Thought Server",
      "factor": 77,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 9.818181818181818,
      "mu_n": 3.4545454545454546,
      "mu_d": 71.54545454545455,
      "n_tools": 11,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 11,
      "tools_count_actual": 11,
      "tools_count_valid": 11,
      "tools_mismatch": false
    },
    {
      "server_id": "@mahecode/mcp-react-native-skia",
      "server_name": "React Native Skia Animation Thinking Tool",
      "factor": 77,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 13.0,
      "mu_n": 4.0,
      "mu_d": 523.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@KISOpenAPI/kis-code-assistant-mcp",
      "server_name": "한국투자 코딩도우미 MCP",
      "factor": 77,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 5.555555555555555,
      "mu_n": 5.0,
      "mu_d": 818.3333333333334,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@trojansaga/git_test",
      "server_name": "Git Test Server",
      "factor": 77,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 7.4,
      "mu_n": 5.8,
      "mu_d": 176.4,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@waldzellai/collaborative-reasoning",
      "server_name": "Collaborative Reasoning Server",
      "factor": 77,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 15.0,
      "mu_n": 5.0,
      "mu_d": 119.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@vitaldb/medcalc",
      "server_name": "Medical Calculation Server",
      "factor": 77,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.454545454545454,
      "mu_n": 4.409090909090909,
      "mu_d": 169.1818181818182,
      "n_tools": 22,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 22,
      "tools_count_actual": 22,
      "tools_count_valid": 22,
      "tools_mismatch": false
    },
    {
      "server_id": "@waldzellai/analogical-reasoning",
      "server_name": "Analogical Reasoning Server",
      "factor": 76,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 12.0,
      "mu_n": 5.0,
      "mu_d": 135.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@xinzhongyouhai/mcp-sequentialthinking-tools",
      "server_name": "Sequential Thinking Tools",
      "factor": 75,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 12.0,
      "mu_n": 3.0,
      "mu_d": 758.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@waldzellai/structured-argumentation",
      "server_name": "Structured Argumentation Server",
      "factor": 75,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 13.0,
      "mu_n": 3.0,
      "mu_d": 267.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@trilogy-group/aws-pricing-mcp",
      "server_name": "AWS EC2 Pricing",
      "factor": 75,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 18.0,
      "mu_n": 2.0,
      "mu_d": 630.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@waldzellai/metacognitive-monitoring",
      "server_name": "Metacognitive Monitoring Server",
      "factor": 75,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 12.0,
      "mu_n": 4.0,
      "mu_d": 129.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@2511319/mcp-sequentialthinking-tools",
      "server_name": "Sequential Thinking Tools Server",
      "factor": 75,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 12.0,
      "mu_n": 3.0,
      "mu_d": 758.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@mahecode/game-engine-mcp",
      "server_name": "Game Engine Server",
      "factor": 73,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 7.666666666666667,
      "mu_n": 3.3333333333333335,
      "mu_d": 208.0,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@waldzellai/visual-reasoning",
      "server_name": "Visual Reasoning Server",
      "factor": 73,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 10.0,
      "mu_n": 3.0,
      "mu_d": 228.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@DynamicEndpoints/powershell-exec-mcp-server",
      "server_name": "PowerShell Exec Server",
      "factor": 73,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.7857142857142856,
      "mu_n": 4.142857142857143,
      "mu_d": 307.85714285714283,
      "n_tools": 14,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 14,
      "tools_count_actual": 14,
      "tools_count_valid": 14,
      "tools_mismatch": false
    },
    {
      "server_id": "@starfishdata/biomcp_test",
      "server_name": "BioMCP",
      "factor": 73,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 6.0,
      "mu_n": 2.4444444444444446,
      "mu_d": 169.33333333333334,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@HenkDz/postgresql-mcp-server",
      "server_name": "PostgreSQL Database Management Server",
      "factor": 73,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 9.833333333333334,
      "mu_n": 3.4444444444444446,
      "mu_d": 35.111111111111114,
      "n_tools": 18,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 18,
      "tools_count_actual": 18,
      "tools_count_valid": 18,
      "tools_mismatch": false
    },
    {
      "server_id": "@waldzellai/decision-framework",
      "server_name": "Decision Framework Server",
      "factor": 73,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 20.0,
      "mu_n": 2.0,
      "mu_d": 115.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ngoiyaeric/open-streetmap-mcp",
      "server_name": "OpenStreetMap Location Services Server",
      "factor": 72,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.083333333333333,
      "mu_n": 3.75,
      "mu_d": 189.66666666666666,
      "n_tools": 12,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 12,
      "tools_count_actual": 12,
      "tools_count_valid": 12,
      "tools_mismatch": false
    },
    {
      "server_id": "@smithery-ai/server-sequential-thinking",
      "server_name": "Sequential Thinking",
      "factor": 71,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 9.0,
      "mu_n": 2.0,
      "mu_d": 565.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@kiennd/reference-servers",
      "server_name": "Sequential Thinking",
      "factor": 71,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 9.0,
      "mu_n": 2.0,
      "mu_d": 565.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@marco280690/mcp",
      "server_name": "Model Context Protocol Server",
      "factor": 71,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 9.0,
      "mu_n": 2.0,
      "mu_d": 565.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@antvis/mcp-server-chart",
      "server_name": "Visualization Charts Server",
      "factor": 71,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 6.76,
      "mu_n": 3.8,
      "mu_d": 36.12,
      "n_tools": 25,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 25,
      "tools_count_actual": 25,
      "tools_count_valid": 25,
      "tools_mismatch": false
    },
    {
      "server_id": "@etweisberg/mlb-mcp",
      "server_name": "MLB Stats Server",
      "factor": 71,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.2888888888888888,
      "mu_n": 4.822222222222222,
      "mu_d": 83.5111111111111,
      "n_tools": 45,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 46,
      "tools_count_actual": 46,
      "tools_count_valid": 45,
      "tools_mismatch": false
    },
    {
      "server_id": "@TanukiMCP/taskmaster",
      "server_name": "Taskmaster",
      "factor": 71,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 13.0,
      "mu_n": 2.0,
      "mu_d": 112.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@rvibek/mcp_unhcr",
      "server_name": "UNHCR Population Data Server",
      "factor": 70,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 5.0,
      "mu_n": 4.333333333333333,
      "mu_d": 346.3333333333333,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@albinjal/multi-agent-debate-mcp",
      "server_name": "Multi-Agent Debate",
      "factor": 69,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 6.0,
      "mu_n": 4.0,
      "mu_d": 219.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@taazkareem/clickup-mcp-server",
      "server_name": "ClickUp MCP Server",
      "factor": 69,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 5.027777777777778,
      "mu_n": 2.7777777777777777,
      "mu_d": 52.083333333333336,
      "n_tools": 36,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 36,
      "tools_count_actual": 36,
      "tools_count_valid": 36,
      "tools_mismatch": false
    },
    {
      "server_id": "@waldzellai/scientific-method",
      "server_name": "Scientific Method Server",
      "factor": 69,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 10.0,
      "mu_n": 2.0,
      "mu_d": 111.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@kbsooo/mcp_atom_of_thoughts",
      "server_name": "Atom of Thoughts",
      "factor": 69,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 6.0,
      "mu_n": 2.3333333333333335,
      "mu_d": 281.6666666666667,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@aukik/clickup-mcp-server",
      "server_name": "ClickUp Task Integration Server",
      "factor": 69,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 5.242424242424242,
      "mu_n": 2.727272727272727,
      "mu_d": 47.93939393939394,
      "n_tools": 33,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 33,
      "tools_count_actual": 33,
      "tools_count_valid": 33,
      "tools_mismatch": false
    },
    {
      "server_id": "@miottid/todoist-mcp",
      "server_name": "Todoist Integration",
      "factor": 67,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.948717948717949,
      "mu_n": 2.8974358974358974,
      "mu_d": 78.33333333333333,
      "n_tools": 39,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 39,
      "tools_count_actual": 39,
      "tools_count_valid": 39,
      "tools_mismatch": false
    },
    {
      "server_id": "@blockscout/mcp-server",
      "server_name": "Blockscout MCP Server",
      "factor": 67,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.7777777777777777,
      "mu_n": 3.7777777777777777,
      "mu_d": 100.11111111111111,
      "n_tools": 18,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 18,
      "tools_count_actual": 18,
      "tools_count_valid": 18,
      "tools_mismatch": false
    },
    {
      "server_id": "@waldzellai/clear-thought",
      "server_name": "Clear Thought 1.5",
      "factor": 66,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 6.0,
      "mu_n": 3.0,
      "mu_d": 127.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "notion",
      "server_name": "Notion",
      "factor": 66,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0714285714285716,
      "mu_n": 3.857142857142857,
      "mu_d": 476.07142857142856,
      "n_tools": 14,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 14,
      "tools_count_actual": 14,
      "tools_count_valid": 14,
      "tools_mismatch": false
    },
    {
      "server_id": "@sseaan/amap-mcp-server",
      "server_name": "高德地图 MCP Server",
      "factor": 66,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.5625,
      "mu_n": 4.6875,
      "mu_d": 89.5,
      "n_tools": 16,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 16,
      "tools_count_actual": 16,
      "tools_count_valid": 16,
      "tools_mismatch": false
    },
    {
      "server_id": "@cameroncooke/XcodeBuildMCP",
      "server_name": "XcodeBuild MCP Server",
      "factor": 66,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.222222222222222,
      "mu_n": 4.074074074074074,
      "mu_d": 37.611111111111114,
      "n_tools": 54,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 54,
      "tools_count_actual": 54,
      "tools_count_valid": 54,
      "tools_mismatch": false
    },
    {
      "server_id": "@cjo4m06/mcp-shrimp-task-manager",
      "server_name": "Shrimp Task Manager",
      "factor": 65,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.8666666666666667,
      "mu_n": 2.2666666666666666,
      "mu_d": 108.53333333333333,
      "n_tools": 15,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 15,
      "tools_count_actual": 15,
      "tools_count_valid": 15,
      "tools_mismatch": false
    },
    {
      "server_id": "@hellokaton/unsplash-mcp-server",
      "server_name": "Unsplash Search",
      "factor": 65,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 6.0,
      "mu_n": 2.0,
      "mu_d": 165.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@GigaChatTester/desktopcommandermcp",
      "server_name": "Desktop Commander",
      "factor": 65,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.9523809523809523,
      "mu_n": 2.619047619047619,
      "mu_d": 214.8095238095238,
      "n_tools": 21,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 21,
      "tools_count_actual": 21,
      "tools_count_valid": 21,
      "tools_mismatch": false
    },
    {
      "server_id": "@linxule/lotus-wisdom-mcp",
      "server_name": "Lotus Wisdom",
      "factor": 64,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.5,
      "mu_n": 4.5,
      "mu_d": 370.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@jason-tan-swe/railway-mcp",
      "server_name": "Railway MCP Server",
      "factor": 64,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.473684210526316,
      "mu_n": 2.3684210526315788,
      "mu_d": 75.97368421052632,
      "n_tools": 38,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 38,
      "tools_count_actual": 38,
      "tools_count_valid": 38,
      "tools_mismatch": false
    },
    {
      "server_id": "@kivilaid/n8n-mcp",
      "server_name": "ennkaheksa",
      "factor": 64,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.9230769230769231,
      "mu_n": 4.230769230769231,
      "mu_d": 72.58974358974359,
      "n_tools": 39,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 39,
      "tools_count_actual": 39,
      "tools_count_valid": 39,
      "tools_mismatch": false
    },
    {
      "server_id": "@docfork/mcp",
      "server_name": "Docfork",
      "factor": 64,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.0,
      "mu_n": 4.0,
      "mu_d": 224.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@emeryray2002/virustotal-mcp",
      "server_name": "VirusTotal MCP Server",
      "factor": 64,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.5,
      "mu_n": 3.1,
      "mu_d": 143.7,
      "n_tools": 10,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 10,
      "tools_count_actual": 10,
      "tools_count_valid": 10,
      "tools_mismatch": false
    },
    {
      "server_id": "@m-ahmed-elbeskeri/ultimatecodermcp",
      "server_name": "UltimateCoder",
      "factor": 64,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.7826086956521738,
      "mu_n": 3.260869565217391,
      "mu_d": 120.26086956521739,
      "n_tools": 23,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 23,
      "tools_count_actual": 23,
      "tools_count_valid": 23,
      "tools_mismatch": false
    },
    {
      "server_id": "@mh8974/railway-mcp",
      "server_name": "Railway MCP Server",
      "factor": 64,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.5833333333333335,
      "mu_n": 2.388888888888889,
      "mu_d": 76.5,
      "n_tools": 36,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 36,
      "tools_count_actual": 36,
      "tools_count_valid": 36,
      "tools_mismatch": false
    },
    {
      "server_id": "@wonderwhy-er/desktop-commander",
      "server_name": "Desktop Commander",
      "factor": 63,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0555555555555554,
      "mu_n": 2.2222222222222223,
      "mu_d": 151.05555555555554,
      "n_tools": 18,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 18,
      "tools_count_actual": 18,
      "tools_count_valid": 18,
      "tools_mismatch": false
    },
    {
      "server_id": "@jzinno/biomart-mcp",
      "server_name": "Biomart MCP",
      "factor": 63,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.625,
      "mu_n": 2.375,
      "mu_d": 209.0,
      "n_tools": 8,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 8,
      "tools_count_actual": 8,
      "tools_count_valid": 8,
      "tools_mismatch": false
    },
    {
      "server_id": "@su-record/hi-ai",
      "server_name": "Hi-AI",
      "factor": 63,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.0606060606060606,
      "mu_n": 3.0,
      "mu_d": 49.90909090909091,
      "n_tools": 33,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 33,
      "tools_count_actual": 33,
      "tools_count_valid": 33,
      "tools_mismatch": false
    },
    {
      "server_id": "@ddltn/raindrop-mcp-python",
      "server_name": "Raindrop.io Bookmark Manager",
      "factor": 62,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.25,
      "mu_n": 3.1666666666666665,
      "mu_d": 60.333333333333336,
      "n_tools": 12,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 12,
      "tools_count_actual": 12,
      "tools_count_valid": 12,
      "tools_mismatch": false
    },
    {
      "server_id": "@shinzo-labs/coinmarketcap-mcp",
      "server_name": "CoinMarketCap MCP",
      "factor": 62,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 5.769230769230769,
      "mu_n": 3.6153846153846154,
      "mu_d": 13.653846153846153,
      "n_tools": 26,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 26,
      "tools_count_actual": 26,
      "tools_count_valid": 26,
      "tools_mismatch": false
    },
    {
      "server_id": "@SmartManoj/google-sheets-mcp",
      "server_name": "Google Sheets MCP",
      "factor": 62,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.526315789473684,
      "mu_n": 3.0,
      "mu_d": 68.73684210526316,
      "n_tools": 19,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 19,
      "tools_count_actual": 19,
      "tools_count_valid": 19,
      "tools_mismatch": false
    },
    {
      "server_id": "@supadata-ai/mcp",
      "server_name": "Supadata: Web & Video data API for makers",
      "factor": 62,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.1666666666666665,
      "mu_n": 4.5,
      "mu_d": 167.0,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@jinkoso/jinko-mcp",
      "server_name": "Hotel Booking Server",
      "factor": 61,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 3.3333333333333335,
      "mu_d": 99.66666666666667,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@Krieg2065/firecrawl-mcp-server",
      "server_name": "Firecrawl Web Scraping Server",
      "factor": 61,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 5.7,
      "mu_n": 4.5,
      "mu_d": 21.1,
      "n_tools": 10,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 10,
      "tools_count_actual": 10,
      "tools_count_valid": 10,
      "tools_mismatch": false
    },
    {
      "server_id": "@aptro/superset-mcp",
      "server_name": "Superset Integration",
      "factor": 61,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.1333333333333333,
      "mu_n": 5.333333333333333,
      "mu_d": 74.48333333333333,
      "n_tools": 60,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 60,
      "tools_count_actual": 60,
      "tools_count_valid": 60,
      "tools_mismatch": false
    },
    {
      "server_id": "@hyperbrowserai/mcp",
      "server_name": "Hyperbrowser",
      "factor": 61,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.1,
      "mu_n": 3.6,
      "mu_d": 63.6,
      "n_tools": 10,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 10,
      "tools_count_actual": 10,
      "tools_count_valid": 10,
      "tools_mismatch": false
    },
    {
      "server_id": "@jmanek/google-news-trends-mcp",
      "server_name": "Google News and Trends",
      "factor": 61,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.2,
      "mu_n": 3.8,
      "mu_d": 61.2,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@cso1z/feishu-mcp",
      "server_name": "Feishu(飞书) Integration Server",
      "factor": 61,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.9230769230769231,
      "mu_n": 6.076923076923077,
      "mu_d": 69.3076923076923,
      "n_tools": 13,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 13,
      "tools_count_actual": 13,
      "tools_count_valid": 13,
      "tools_mismatch": false
    },
    {
      "server_id": "@horizondatawave/hdw-mcp-server",
      "server_name": "HDW MCP Server",
      "factor": 61,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.954545454545454,
      "mu_n": 4.681818181818182,
      "mu_d": 14.181818181818182,
      "n_tools": 22,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 22,
      "tools_count_actual": 22,
      "tools_count_valid": 22,
      "tools_mismatch": false
    },
    {
      "server_id": "@browserbasehq/mcp-browserbase",
      "server_name": "Browserbase",
      "factor": 60,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.2941176470588236,
      "mu_n": 6.235294117647059,
      "mu_d": 75.3529411764706,
      "n_tools": 17,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 17,
      "tools_count_actual": 17,
      "tools_count_valid": 17,
      "tools_mismatch": false
    },
    {
      "server_id": "@imbenrabi/financial-modeling-prep-mcp-server",
      "server_name": "Financial Modeling Prep (FMP) Server ",
      "factor": 60,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0316205533596836,
      "mu_n": 4.561264822134388,
      "mu_d": 41.19762845849802,
      "n_tools": 253,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 253,
      "tools_count_actual": 253,
      "tools_count_valid": 253,
      "tools_mismatch": false
    },
    {
      "server_id": "@isnow890/naver-search-mcp",
      "server_name": "Naver Search",
      "factor": 60,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.5,
      "mu_n": 4.05,
      "mu_d": 19.75,
      "n_tools": 20,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 20,
      "tools_count_actual": 20,
      "tools_count_valid": 20,
      "tools_mismatch": false
    },
    {
      "server_id": "@guangxiangdebizi/FinanceMCP",
      "server_name": "Tushare_Finance_Data",
      "factor": 60,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.3529411764705883,
      "mu_n": 3.0,
      "mu_d": 38.470588235294116,
      "n_tools": 17,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 17,
      "tools_count_actual": 17,
      "tools_count_valid": 17,
      "tools_mismatch": false
    },
    {
      "server_id": "@Aman-Amith-Shastry/scientific_computation_mcp",
      "server_name": "Scientific Computation MCP Server",
      "factor": 60,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.8076923076923077,
      "mu_n": 2.423076923076923,
      "mu_d": 82.76923076923077,
      "n_tools": 26,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 26,
      "tools_count_actual": 26,
      "tools_count_valid": 26,
      "tools_mismatch": false
    },
    {
      "server_id": "@vijitdaroch/financial-modeling-prep-mcp-server",
      "server_name": "Financial Modeling Prep MCP Server",
      "factor": 60,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0316205533596836,
      "mu_n": 4.561264822134388,
      "mu_d": 41.19762845849802,
      "n_tools": 253,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 253,
      "tools_count_actual": 253,
      "tools_count_valid": 253,
      "tools_mismatch": false
    },
    {
      "server_id": "@guangxiangdebizi/finance-mcp",
      "server_name": "FinanceMCP Server",
      "factor": 60,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.3529411764705883,
      "mu_n": 3.0,
      "mu_d": 38.470588235294116,
      "n_tools": 17,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 17,
      "tools_count_actual": 17,
      "tools_count_valid": 17,
      "tools_mismatch": false
    },
    {
      "server_id": "@smithery-ai/migration-guide-mcp",
      "server_name": "Smithery Migration",
      "factor": 60,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 5.6,
      "mu_n": 4.0,
      "mu_d": 31.8,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@smithery-ai/github",
      "server_name": "Github",
      "factor": 59,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 5.2727272727272725,
      "mu_n": 2.8181818181818183,
      "mu_d": 11.93939393939394,
      "n_tools": 33,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 33,
      "tools_count_actual": 33,
      "tools_count_valid": 33,
      "tools_mismatch": false
    },
    {
      "server_id": "@leescot/pubmed-mcp-smithery",
      "server_name": "PubMed Enhanced Search Server",
      "factor": 59,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.2,
      "mu_n": 3.2,
      "mu_d": 128.8,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@ngoiyaeric/earthdata-mcp-server",
      "server_name": "EarthData MCP Server",
      "factor": 59,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 4.0,
      "mu_d": 61.4,
      "n_tools": 15,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 15,
      "tools_count_actual": 15,
      "tools_count_valid": 15,
      "tools_mismatch": false
    },
    {
      "server_id": "@Medinios/SuricataMCP",
      "server_name": "Suricata Network Traffic Analysis Server",
      "factor": 59,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 6.5,
      "mu_d": 141.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@amalinakurniasari/figmamcp",
      "server_name": "Conduit for Figma",
      "factor": 59,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.2816901408450705,
      "mu_n": 2.507042253521127,
      "mu_d": 47.647887323943664,
      "n_tools": 71,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 74,
      "tools_count_actual": 74,
      "tools_count_valid": 71,
      "tools_mismatch": false
    },
    {
      "server_id": "@redis/mcp-redis",
      "server_name": "Redis",
      "factor": 59,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0681818181818183,
      "mu_n": 2.0681818181818183,
      "mu_d": 55.72727272727273,
      "n_tools": 44,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 44,
      "tools_count_actual": 44,
      "tools_count_valid": 44,
      "tools_mismatch": false
    },
    {
      "server_id": "@Fibery-inc/fibery-mcp-server",
      "server_name": "Fibery MCP Server",
      "factor": 59,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 2.2857142857142856,
      "mu_d": 198.0,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@ScrapeGraphAI/scrapegraph-mcp",
      "server_name": "ScrapeGraph AI Integration Server",
      "factor": 59,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 3.2,
      "mu_d": 81.6,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@devfurkank/wallhaven-mcp",
      "server_name": "Wallhaven Wallpaper Search Server",
      "factor": 58,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.1666666666666665,
      "mu_n": 3.0,
      "mu_d": 63.166666666666664,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@alperenkocyigit/semantic-scholar-graph-api",
      "server_name": "Semantic Scholar Academic Research MCP",
      "factor": 58,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 8.583333333333334,
      "mu_d": 50.75,
      "n_tools": 12,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 12,
      "tools_count_actual": 12,
      "tools_count_valid": 12,
      "tools_mismatch": false
    },
    {
      "server_id": "@haris-musa/excel-mcp-server",
      "server_name": "Excel MCP Server",
      "factor": 58,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.44,
      "mu_n": 2.84,
      "mu_d": 17.8,
      "n_tools": 25,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 25,
      "tools_count_actual": 25,
      "tools_count_valid": 25,
      "tools_mismatch": false
    },
    {
      "server_id": "@watsonchua/poker_win_calculator",
      "server_name": "Poker Win Calculator",
      "factor": 58,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 5.0,
      "mu_d": 172.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@clay-inc/clay-mcp",
      "server_name": "Clay MCP",
      "factor": 58,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.8181818181818183,
      "mu_n": 2.090909090909091,
      "mu_d": 41.18181818181818,
      "n_tools": 11,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 11,
      "tools_count_actual": 11,
      "tools_count_valid": 11,
      "tools_mismatch": false
    },
    {
      "server_id": "@kazuph/mcp-taskmanager",
      "server_name": "TaskManager",
      "factor": 58,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.9,
      "mu_n": 2.8,
      "mu_d": 90.5,
      "n_tools": 10,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 10,
      "tools_count_actual": 10,
      "tools_count_valid": 10,
      "tools_mismatch": false
    },
    {
      "server_id": "@CelalKhalilov/koran-mcp",
      "server_name": "Kuran-ı Kerim Quran API Server",
      "factor": 58,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0833333333333335,
      "mu_n": 4.916666666666667,
      "mu_d": 54.083333333333336,
      "n_tools": 12,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 12,
      "tools_count_actual": 12,
      "tools_count_valid": 12,
      "tools_mismatch": false
    },
    {
      "server_id": "@AkekaratP/mcp-server-airbnb",
      "server_name": "Airbnb Search and Listing Details Server",
      "factor": 57,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 10.0,
      "mu_n": 3.5,
      "mu_d": 15.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@JackKuo666/clinicaltrials-mcp-server",
      "server_name": "ClinicalTrials MCP Server",
      "factor": 57,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.142857142857143,
      "mu_n": 5.142857142857143,
      "mu_d": 60.57142857142857,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@pinkpixel-dev/mcpollinations",
      "server_name": "MCPollinations Multimodal Server",
      "factor": 57,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 5.777777777777778,
      "mu_n": 2.6666666666666665,
      "mu_d": 19.666666666666668,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@openbnb-org/mcp-server-airbnb",
      "server_name": "Airbnb Search and Listing Server",
      "factor": 57,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 10.0,
      "mu_n": 3.5,
      "mu_d": 15.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@openags/paper-search-mcp",
      "server_name": "Paper Search",
      "factor": 57,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.923076923076923,
      "mu_d": 55.23076923076923,
      "n_tools": 13,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 13,
      "tools_count_actual": 13,
      "tools_count_valid": 13,
      "tools_mismatch": false
    },
    {
      "server_id": "@geobio/mcp-server-airbnb",
      "server_name": "Airbnb Search and Listing Details Server",
      "factor": 57,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 10.0,
      "mu_n": 3.5,
      "mu_d": 15.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@batprem/set-mcp",
      "server_name": "SET-MCP",
      "factor": 57,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 4.0,
      "mu_d": 105.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@wildfly-extras/wildfly-mcp-server",
      "server_name": "WildFly MCP Server",
      "factor": 57,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.2,
      "mu_n": 5.3,
      "mu_d": 19.9,
      "n_tools": 10,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 10,
      "tools_count_actual": 10,
      "tools_count_valid": 10,
      "tools_mismatch": false
    },
    {
      "server_id": "@Swayingleaves/uml-mcp-server",
      "server_name": "UML Diagram Generation Tool",
      "factor": 57,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.1,
      "mu_n": 4.2,
      "mu_d": 60.1,
      "n_tools": 10,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 10,
      "tools_count_actual": 10,
      "tools_count_valid": 10,
      "tools_mismatch": false
    },
    {
      "server_id": "@kirbah/mcp-youtube",
      "server_name": "YouTube Data Server",
      "factor": 57,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.2857142857142856,
      "mu_n": 3.142857142857143,
      "mu_d": 46.42857142857143,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@appwrite/mcp",
      "server_name": "Appwrite MCP Server",
      "factor": 57,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.928571428571429,
      "mu_n": 4.357142857142857,
      "mu_d": 2.5238095238095237,
      "n_tools": 42,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 42,
      "tools_count_actual": 42,
      "tools_count_valid": 42,
      "tools_mismatch": false
    },
    {
      "server_id": "@smithery/notion",
      "server_name": "Notion",
      "factor": 56,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.1333333333333333,
      "mu_n": 2.6,
      "mu_d": 34.2,
      "n_tools": 15,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 15,
      "tools_count_actual": 15,
      "tools_count_valid": 15,
      "tools_mismatch": false
    },
    {
      "server_id": "@GongRzhe/terminal-controller-mcp",
      "server_name": "Terminal Controller",
      "factor": 56,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.5,
      "mu_n": 2.5,
      "mu_d": 56.1,
      "n_tools": 10,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 10,
      "tools_count_actual": 10,
      "tools_count_valid": 10,
      "tools_mismatch": false
    },
    {
      "server_id": "@telegramtool/crypto_mcp",
      "server_name": "虚拟币价格查询服务",
      "factor": 56,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.5833333333333333,
      "mu_n": 3.5,
      "mu_d": 69.66666666666667,
      "n_tools": 12,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 12,
      "tools_count_actual": 12,
      "tools_count_valid": 12,
      "tools_mismatch": false
    },
    {
      "server_id": "@WTTeneger/food-tracker-mcp",
      "server_name": "Food Tracker",
      "factor": 56,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.7142857142857144,
      "mu_n": 3.857142857142857,
      "mu_d": 50.142857142857146,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@jkingsman/qanon-mcp-server",
      "server_name": "Q-Anon Posts/Drops Server",
      "factor": 56,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.375,
      "mu_n": 3.875,
      "mu_d": 51.25,
      "n_tools": 8,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 8,
      "tools_count_actual": 8,
      "tools_count_valid": 8,
      "tools_mismatch": false
    },
    {
      "server_id": "@advenimus/jw-mcp",
      "server_name": "JW.org Content Tools",
      "factor": 56,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.2,
      "mu_n": 4.0,
      "mu_d": 78.6,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@afarhadi99/wordpress-mcp-full",
      "server_name": "WordPress & WooCommerce API Server",
      "factor": 56,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.3307692307692305,
      "mu_n": 3.6923076923076925,
      "mu_d": 5.369230769230769,
      "n_tools": 130,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 130,
      "tools_count_actual": 130,
      "tools_count_valid": 130,
      "tools_mismatch": false
    },
    {
      "server_id": "@m0xai/trello-mcp-server",
      "server_name": "Trello MCP Server",
      "factor": 56,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.7272727272727273,
      "mu_n": 2.5454545454545454,
      "mu_d": 53.36363636363637,
      "n_tools": 22,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 22,
      "tools_count_actual": 22,
      "tools_count_valid": 22,
      "tools_mismatch": false
    },
    {
      "server_id": "@gvzq/flight-mcp",
      "server_name": "Flight Search MCP Server",
      "factor": 56,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.0,
      "mu_n": 2.75,
      "mu_d": 50.5,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@MeterLong/mcp-doc",
      "server_name": "Docx Document Processing Service",
      "factor": 56,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.260869565217391,
      "mu_n": 2.608695652173913,
      "mu_d": 37.69565217391305,
      "n_tools": 23,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 23,
      "tools_count_actual": 23,
      "tools_count_valid": 23,
      "tools_mismatch": false
    },
    {
      "server_id": "linear",
      "server_name": "Linear",
      "factor": 56,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 5.458333333333333,
      "mu_n": 2.2916666666666665,
      "mu_d": 7.833333333333333,
      "n_tools": 24,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 24,
      "tools_count_actual": 24,
      "tools_count_valid": 24,
      "tools_mismatch": false
    },
    {
      "server_id": "@greirson/mcp-todoist",
      "server_name": "Todoist Task Manager",
      "factor": 56,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.25,
      "mu_n": 4.5,
      "mu_d": 13.714285714285714,
      "n_tools": 28,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 28,
      "tools_count_actual": 28,
      "tools_count_valid": 28,
      "tools_mismatch": false
    },
    {
      "server_id": "@upstash/context7-mcp",
      "server_name": "Context7",
      "factor": 55,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.5,
      "mu_d": 142.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@kkjdaniel/bgg-mcp",
      "server_name": "BoardGameGeek API Server",
      "factor": 55,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.6,
      "mu_n": 3.6,
      "mu_d": 24.9,
      "n_tools": 10,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 10,
      "tools_count_actual": 10,
      "tools_count_valid": 10,
      "tools_mismatch": false
    },
    {
      "server_id": "@geobio/context7",
      "server_name": "Context7",
      "factor": 55,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.5,
      "mu_d": 142.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@jikime/py-mcp-naver-search",
      "server_name": "Naver Search",
      "factor": 55,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.4615384615384617,
      "mu_n": 2.769230769230769,
      "mu_d": 25.615384615384617,
      "n_tools": 13,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 13,
      "tools_count_actual": 13,
      "tools_count_valid": 13,
      "tools_mismatch": false
    },
    {
      "server_id": "@walidboulanouar/n8n-mcp",
      "server_name": "n8n Workflow Automation Server",
      "factor": 55,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.9487179487179487,
      "mu_n": 4.230769230769231,
      "mu_d": 25.53846153846154,
      "n_tools": 39,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 39,
      "tools_count_actual": 39,
      "tools_count_valid": 39,
      "tools_mismatch": false
    },
    {
      "server_id": "@samihalawa/tusclasesparticulares-mcp",
      "server_name": "TusClasesParticulares Automation Server",
      "factor": 55,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.95,
      "mu_n": 9.75,
      "mu_d": 8.0,
      "n_tools": 20,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 20,
      "tools_count_actual": 20,
      "tools_count_valid": 20,
      "tools_mismatch": false
    },
    {
      "server_id": "@Hint-Services/mcp-limitless",
      "server_name": "Limitless AI Lifelog Access",
      "factor": 55,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.666666666666667,
      "mu_n": 5.0,
      "mu_d": 27.333333333333332,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@mochow13/google-scholar-mcp",
      "server_name": "Google Scholar Search Server",
      "factor": 55,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 5.0,
      "mu_n": 5.0,
      "mu_d": 34.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "exa",
      "server_name": "Exa Search",
      "factor": 54,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 4.5,
      "mu_d": 86.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@mcpdotdirect/starknet-mcp-server",
      "server_name": "Starknet MCP Server",
      "factor": 54,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.84,
      "mu_n": 5.84,
      "mu_d": 9.36,
      "n_tools": 25,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 25,
      "tools_count_actual": 25,
      "tools_count_valid": 25,
      "tools_mismatch": false
    },
    {
      "server_id": "@Ilaydauygun/dog_mcp",
      "server_name": "Dog Image Fetcher",
      "factor": 54,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.5,
      "mu_n": 5.0,
      "mu_d": 50.0,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@gradusnikov/pubmed-search-mcp-server",
      "server_name": "PubMedSearch",
      "factor": 54,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 124.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@liorfranko/mcp-chain-of-thought",
      "server_name": "Chain of Thought",
      "factor": 54,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.6,
      "mu_n": 2.2666666666666666,
      "mu_d": 36.86666666666667,
      "n_tools": 15,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 15,
      "tools_count_actual": 15,
      "tools_count_valid": 15,
      "tools_mismatch": false
    },
    {
      "server_id": "@alperenkocyigit/authorprofilemcp",
      "server_name": "Academic Author Network",
      "factor": 54,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.5,
      "mu_n": 3.0,
      "mu_d": 58.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@chenyeju295/ios_migration_mcp",
      "server_name": "iOS Code Migration Optimization Tool",
      "factor": 54,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.2857142857142856,
      "mu_n": 3.857142857142857,
      "mu_d": 47.285714285714285,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@prashalruchiranga/arxiv-mcp-server",
      "server_name": "arXiv MCP Server",
      "factor": 54,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.8,
      "mu_n": 2.8,
      "mu_d": 97.0,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@burtthecoder/mcp-shodan",
      "server_name": "Shodan Server",
      "factor": 54,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.7142857142857144,
      "mu_n": 3.0,
      "mu_d": 45.42857142857143,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@INSIDE-HAIR/mcp-google-meet-and-calendar",
      "server_name": "Google Calendar and Meet",
      "factor": 54,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.6923076923076925,
      "mu_n": 5.576923076923077,
      "mu_d": 13.153846153846153,
      "n_tools": 26,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 26,
      "tools_count_actual": 26,
      "tools_count_valid": 26,
      "tools_mismatch": false
    },
    {
      "server_id": "@robawolf/mcp-sanity",
      "server_name": "Sanity.io MCP Server",
      "factor": 54,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.176470588235294,
      "mu_n": 2.5588235294117645,
      "mu_d": 15.352941176470589,
      "n_tools": 34,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 34,
      "tools_count_actual": 34,
      "tools_count_valid": 34,
      "tools_mismatch": false
    },
    {
      "server_id": "@ruradium/mcp-reddit",
      "server_name": "Reddit Content Fetcher",
      "factor": 53,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.5,
      "mu_n": 5.0,
      "mu_d": 54.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@janwilmake/openapi-mcp-server",
      "server_name": "OpenAPI MCP Server",
      "factor": 53,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 2.5,
      "mu_d": 819.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@anirbanbasu/frankfurtermcp",
      "server_name": "FrankfurterMCP",
      "factor": 53,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.8,
      "mu_n": 4.0,
      "mu_d": 38.4,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@brianirish/laravel-mcp-companion",
      "server_name": "Laravel MCP Companion",
      "factor": 53,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.625,
      "mu_n": 4.6875,
      "mu_d": 33.75,
      "n_tools": 16,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 16,
      "tools_count_actual": 16,
      "tools_count_valid": 16,
      "tools_mismatch": false
    },
    {
      "server_id": "@GongRzhe/Office-Word-MCP-Server",
      "server_name": "Office Word Document Server",
      "factor": 53,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.1481481481481484,
      "mu_n": 3.074074074074074,
      "mu_d": 12.333333333333334,
      "n_tools": 27,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 27,
      "tools_count_actual": 27,
      "tools_count_valid": 27,
      "tools_mismatch": false
    },
    {
      "server_id": "@ssdavidai/mssql-mcp",
      "server_name": "MSSQL Server Integration",
      "factor": 53,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.125,
      "mu_n": 2.0,
      "mu_d": 60.5,
      "n_tools": 8,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 8,
      "tools_count_actual": 8,
      "tools_count_valid": 8,
      "tools_mismatch": false
    },
    {
      "server_id": "@JeremyNixon/mcp-fetch-me",
      "server_name": "MCP Fetch",
      "factor": 53,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.0,
      "mu_n": 1.0,
      "mu_d": 73.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ahujasid/ableton-mcp",
      "server_name": "Ableton Live Integration",
      "factor": 53,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.5625,
      "mu_n": 3.3125,
      "mu_d": 42.9375,
      "n_tools": 16,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 16,
      "tools_count_actual": 16,
      "tools_count_valid": 16,
      "tools_mismatch": false
    },
    {
      "server_id": "@kydycode/todoist-mcp-server-ext",
      "server_name": "Todoist Extended MCP Server",
      "factor": 53,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.9,
      "mu_n": 4.1,
      "mu_d": 10.933333333333334,
      "n_tools": 30,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 30,
      "tools_count_actual": 30,
      "tools_count_valid": 30,
      "tools_mismatch": false
    },
    {
      "server_id": "@iremaltunay55/deneme1",
      "server_name": "Weather Forecast Server",
      "factor": 52,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.8,
      "mu_n": 3.4,
      "mu_d": 64.4,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@jikime/py-mcp-youtube-toolbox",
      "server_name": "YouTube Toolbox",
      "factor": 52,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.125,
      "mu_n": 3.625,
      "mu_d": 15.5,
      "n_tools": 8,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 8,
      "tools_count_actual": 8,
      "tools_count_valid": 8,
      "tools_mismatch": false
    },
    {
      "server_id": "@iremaltunay55/denemem",
      "server_name": "Weather Forecast Server with AI Assistant",
      "factor": 52,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.8,
      "mu_n": 3.4,
      "mu_d": 64.4,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@iremaltunay55/deneme",
      "server_name": "Deneme MCP Server",
      "factor": 52,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.8,
      "mu_n": 3.4,
      "mu_d": 64.4,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@PawNzZi/image-server",
      "server_name": "text2image",
      "factor": 52,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 2.0,
      "mu_d": 76.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@velt-js/velt-analytics-mcp",
      "server_name": "Velt Analytics Server",
      "factor": 52,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 5.333333333333333,
      "mu_d": 74.83333333333333,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@gradusnikov/google-search-mcp-server",
      "server_name": "Google Search Server",
      "factor": 52,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 2.0,
      "mu_d": 150.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ohhan777/korea_weather",
      "server_name": "Korea Weather",
      "factor": 52,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 5.0,
      "mu_d": 57.333333333333336,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@cjinzy/stealthmole-mcp-server",
      "server_name": "StealthMole Search Server Stable",
      "factor": 52,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.3684210526315788,
      "mu_n": 3.736842105263158,
      "mu_d": 9.842105263157896,
      "n_tools": 19,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 19,
      "tools_count_actual": 19,
      "tools_count_valid": 19,
      "tools_mismatch": false
    },
    {
      "server_id": "@baranwang/mcp-trends-hub",
      "server_name": "Trends Hub",
      "factor": 51,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 0.8636363636363636,
      "mu_n": 5.545454545454546,
      "mu_d": 34.77272727272727,
      "n_tools": 22,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 22,
      "tools_count_actual": 22,
      "tools_count_valid": 22,
      "tools_mismatch": false
    },
    {
      "server_id": "@vincentmcleese/n8n-mcp",
      "server_name": "n8n MCP Server",
      "factor": 51,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.6363636363636365,
      "mu_n": 3.1363636363636362,
      "mu_d": 29.863636363636363,
      "n_tools": 22,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 22,
      "tools_count_actual": 22,
      "tools_count_valid": 22,
      "tools_mismatch": false
    },
    {
      "server_id": "@tacticlaunch/mcp-linear",
      "server_name": "Linear",
      "factor": 51,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.738095238095238,
      "mu_n": 3.857142857142857,
      "mu_d": 6.761904761904762,
      "n_tools": 42,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 42,
      "tools_count_actual": 42,
      "tools_count_valid": 42,
      "tools_mismatch": false
    },
    {
      "server_id": "@nic0xflamel/coingecko-mcp-server",
      "server_name": "CoinGecko API Server",
      "factor": 51,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 5.142857142857143,
      "mu_n": 4.285714285714286,
      "mu_d": 4.428571428571429,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@zxsimple/reference-servers",
      "server_name": "Fetch Server",
      "factor": 51,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.0,
      "mu_n": 1.0,
      "mu_d": 60.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@antonioevans/context7",
      "server_name": "Context7",
      "factor": 51,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.5,
      "mu_d": 69.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@tywenk/mcp-solana",
      "server_name": "Solana Client",
      "factor": 51,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 0.8409090909090909,
      "mu_n": 3.340909090909091,
      "mu_d": 39.02272727272727,
      "n_tools": 44,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 44,
      "tools_count_actual": 44,
      "tools_count_valid": 44,
      "tools_mismatch": false
    },
    {
      "server_id": "@jiankaitian/servers",
      "server_name": "Fetch Server",
      "factor": 51,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.0,
      "mu_n": 1.0,
      "mu_d": 60.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@JackKuo666/chembl-mcp-server",
      "server_name": "ChEMBL Server",
      "factor": 51,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 4.021739130434782,
      "mu_d": 31.782608695652176,
      "n_tools": 46,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 46,
      "tools_count_actual": 46,
      "tools_count_valid": 46,
      "tools_mismatch": false
    },
    {
      "server_id": "@iamadk/fetch",
      "server_name": "Fetch Server",
      "factor": 51,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 4.0,
      "mu_n": 1.0,
      "mu_d": 60.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@inventer-dev/mcp-internet-speed-test",
      "server_name": "Internet Speed Test",
      "factor": 51,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 2.8333333333333335,
      "mu_d": 53.666666666666664,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@hwruchan/chanmcp",
      "server_name": "chanmcp Server",
      "factor": 51,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.1428571428571428,
      "mu_n": 5.428571428571429,
      "mu_d": 55.142857142857146,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@hamid-vakilzadeh/mcpsemanticscholar",
      "server_name": "AI Research Assistant",
      "factor": 50,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.142857142857143,
      "mu_n": 3.5,
      "mu_d": 9.857142857142858,
      "n_tools": 14,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 14,
      "tools_count_actual": 14,
      "tools_count_valid": 14,
      "tools_mismatch": false
    },
    {
      "server_id": "@mzdz/calc-mcp-server",
      "server_name": "计算器(Calc MCP)",
      "factor": 50,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.7142857142857142,
      "mu_n": 1.1428571428571428,
      "mu_d": 74.57142857142857,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@lieyanqzu/opendota-mcp-server",
      "server_name": "OpenDota API Server",
      "factor": 50,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 1.1176470588235294,
      "mu_n": 3.411764705882353,
      "mu_d": 36.0,
      "n_tools": 17,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 17,
      "tools_count_actual": 17,
      "tools_count_valid": 17,
      "tools_mismatch": false
    },
    {
      "server_id": "@doggybee/mcp-server-ccxt",
      "server_name": "CCXT MCP Server",
      "factor": 50,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.0416666666666665,
      "mu_n": 3.375,
      "mu_d": 6.583333333333333,
      "n_tools": 24,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 24,
      "tools_count_actual": 24,
      "tools_count_valid": 24,
      "tools_mismatch": false
    },
    {
      "server_id": "@jackxzxz/office-word-mcp-server",
      "server_name": "Office Word Document Server",
      "factor": 50,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.0833333333333335,
      "mu_n": 2.9166666666666665,
      "mu_d": 9.0,
      "n_tools": 24,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 24,
      "tools_count_actual": 24,
      "tools_count_valid": 24,
      "tools_mismatch": false
    },
    {
      "server_id": "@blake365/macrostrat-mcp",
      "server_name": "Macrostrat API Server",
      "factor": 50,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.875,
      "mu_n": 2.875,
      "mu_d": 24.125,
      "n_tools": 8,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 8,
      "tools_count_actual": 8,
      "tools_count_valid": 8,
      "tools_mismatch": false
    },
    {
      "server_id": "@hbg/mcp-paperswithcode",
      "server_name": "PapersWithCode Client",
      "factor": 50,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 2.6,
      "mu_n": 3.95,
      "mu_d": 10.8,
      "n_tools": 20,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 20,
      "tools_count_actual": 20,
      "tools_count_valid": 20,
      "tools_mismatch": false
    },
    {
      "server_id": "@infranodus/mcp-server-infranodus",
      "server_name": "InfraNodus Knowledge Graphs & Text Analysis",
      "factor": 50,
      "level": "Hard",
      "threshold": 50,
      "mu_p": 3.090909090909091,
      "mu_n": 3.727272727272727,
      "mu_d": 13.909090909090908,
      "n_tools": 11,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 11,
      "tools_count_actual": 11,
      "tools_count_valid": 11,
      "tools_mismatch": false
    },
    {
      "server_id": "@smithery-ai/national-weather-service",
      "server_name": "United States Weather",
      "factor": 49,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.6666666666666667,
      "mu_n": 3.8333333333333335,
      "mu_d": 41.5,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@Dakkshin/after-effects-mcp",
      "server_name": "After Effects MCP Server",
      "factor": 49,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.1538461538461537,
      "mu_n": 3.6153846153846154,
      "mu_d": 9.846153846153847,
      "n_tools": 13,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 13,
      "tools_count_actual": 13,
      "tools_count_valid": 13,
      "tools_mismatch": false
    },
    {
      "server_id": "@bitrefill/bitrefill-mcp-server",
      "server_name": "Bitrefill MCP Server",
      "factor": 49,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 5.0,
      "mu_n": 1.0,
      "mu_d": 27.0,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@L3-N0X/Minecraft-Wiki-MCP",
      "server_name": "Minecraft Wiki Server",
      "factor": 49,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.3333333333333333,
      "mu_n": 5.888888888888889,
      "mu_d": 30.444444444444443,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@RabiaDogan41/mcp",
      "server_name": "Cultural Heritage Server",
      "factor": 49,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.25,
      "mu_n": 5.0,
      "mu_d": 57.5,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@ibrahimsaleem/pentestthinkingmcp",
      "server_name": "PentestThinking ",
      "factor": 49,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 5.0,
      "mu_n": 5.0,
      "mu_d": 14.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@CelalKhalilov/emoji-hub-mcp",
      "server_name": "Emoji Hub Server",
      "factor": 49,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.6666666666666666,
      "mu_n": 6.5,
      "mu_d": 54.0,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@aryankeluskar/canvas-mcp",
      "server_name": "Canvas MCP",
      "factor": 49,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.2857142857142858,
      "mu_n": 3.2857142857142856,
      "mu_d": 50.142857142857146,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@santoshray02/csv-editor",
      "server_name": "CSV Editor",
      "factor": 49,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.7435897435897436,
      "mu_n": 2.5641025641025643,
      "mu_d": 7.487179487179487,
      "n_tools": 39,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 39,
      "tools_count_actual": 39,
      "tools_count_valid": 39,
      "tools_mismatch": false
    },
    {
      "server_id": "@javilujann/pdftomd-converter",
      "server_name": "PDF to Markdown Converter",
      "factor": 49,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 4.0,
      "mu_d": 64.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@xinkuang/china-stock-mcp",
      "server_name": "China Stock Insights",
      "factor": 49,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 3.5714285714285716,
      "mu_d": 9.714285714285714,
      "n_tools": 14,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 14,
      "tools_count_actual": 14,
      "tools_count_valid": 14,
      "tools_mismatch": false
    },
    {
      "server_id": "@basicmachines-co/basic-memory",
      "server_name": "Basic Memory",
      "factor": 49,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.111111111111111,
      "mu_n": 1.7777777777777777,
      "mu_d": 23.88888888888889,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@falahgs/flux-imagegen-mcp-server",
      "server_name": "Flux ImageGen Server",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 5.666666666666667,
      "mu_n": 2.3333333333333335,
      "mu_d": 10.0,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@sondotpin/desktopcommandermcp",
      "server_name": "Desktop Commander",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.45,
      "mu_n": 2.35,
      "mu_d": 29.05,
      "n_tools": 20,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 20,
      "tools_count_actual": 20,
      "tools_count_valid": 20,
      "tools_mismatch": false
    },
    {
      "server_id": "@BioContext/pubchem-mcp",
      "server_name": "PubChem Data Access Server",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.4,
      "mu_n": 3.8,
      "mu_d": 48.0,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@cantian-ai/bazi-mcp",
      "server_name": "Bazi Calculator",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.4,
      "mu_n": 4.6,
      "mu_d": 24.4,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@pwh-pwh/coin-mcp-server",
      "server_name": "Coin MCP Server",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.3333333333333335,
      "mu_d": 85.0,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@martin-songzy/coin-mcp-server",
      "server_name": "Coin Price Fetcher",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.3333333333333335,
      "mu_d": 85.0,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@611711Dark/mcp_sympy_calculate_server",
      "server_name": "Calculate Server",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 521.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@hydavinci/formula-1-schedule",
      "server_name": "Formula 1 Schedule",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 5.25,
      "mu_d": 55.5,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@the0807/geeknews-mcp-server",
      "server_name": "GeekNews Server",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 3.0,
      "mu_d": 73.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@DynamicEndpoints/autogen_mcp",
      "server_name": "AutoGen Server",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 4.2,
      "mu_n": 3.8,
      "mu_d": 9.4,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@iremaltunay55/weatherapi0",
      "server_name": "Weather API Server",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 66.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@iremaltunay55/weatherapi",
      "server_name": "Weather API Server",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 66.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@babo072/schoolfoods",
      "server_name": "SchoolFoods",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 4.0,
      "mu_d": 58.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@chenmingkong/bilibili-mcp-server",
      "server_name": "Bilibili API Server",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 3.5,
      "mu_d": 51.5,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@iremaltunay55/weatherapi1",
      "server_name": "Weather API Server",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 66.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@nic0xflamel/defillama-mcp",
      "server_name": "DefiLlama API Server",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 6.375,
      "mu_d": 13.4375,
      "n_tools": 16,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 16,
      "tools_count_actual": 16,
      "tools_count_valid": 16,
      "tools_mismatch": false
    },
    {
      "server_id": "@TKelvyn/mcp",
      "server_name": "mcp max",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 6.0,
      "mu_n": 3.0,
      "mu_d": 9.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@DevWebDJ/frappe_mcp_server",
      "server_name": "Frappe Framework Integration Server",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.1,
      "mu_n": 3.35,
      "mu_d": 11.7,
      "n_tools": 20,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 20,
      "tools_count_actual": 20,
      "tools_count_valid": 20,
      "tools_mismatch": false
    },
    {
      "server_id": "@Hint-Services/obsidian-github-mcp",
      "server_name": "Obsidian GitHub",
      "factor": 48,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.2,
      "mu_n": 2.6,
      "mu_d": 39.8,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@mikechao/metmuseum-mcp",
      "server_name": "Met Museum Server",
      "factor": 47,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 4.333333333333333,
      "mu_d": 35.666666666666664,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@adalovu/mcp-playwright",
      "server_name": "Playwright Automation Server",
      "factor": 47,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.9,
      "mu_n": 3.7333333333333334,
      "mu_d": 7.866666666666666,
      "n_tools": 30,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 30,
      "tools_count_actual": 30,
      "tools_count_valid": 30,
      "tools_mismatch": false
    },
    {
      "server_id": "@KR-NOTEPAD/mcp-forestfire-server",
      "server_name": "Current Forest Fire Status in Korea",
      "factor": 47,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 4.4,
      "mu_d": 52.4,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@611711Dark/mcp_python_exec_server",
      "server_name": "Python Safe Sandbox Execution Server",
      "factor": 47,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 170.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@hydavinci/chromium-commits",
      "server_name": "Chromium Latest Commit",
      "factor": 47,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 5.0,
      "mu_d": 75.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@danielkennedy1/pdf-tools-mcp",
      "server_name": "PDF Tools",
      "factor": 47,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.9,
      "mu_n": 3.3,
      "mu_d": 21.9,
      "n_tools": 10,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 10,
      "tools_count_actual": 10,
      "tools_count_valid": 10,
      "tools_mismatch": false
    },
    {
      "server_id": "@makeplane/plane-mcp-server",
      "server_name": "Plane Server",
      "factor": 47,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0869565217391304,
      "mu_n": 2.5434782608695654,
      "mu_d": 9.891304347826088,
      "n_tools": 46,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 46,
      "tools_count_actual": 46,
      "tools_count_valid": 46,
      "tools_mismatch": false
    },
    {
      "server_id": "@geobio/mcp-server-nationalparks",
      "server_name": "National Parks Information Server",
      "factor": 47,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 4.0,
      "mu_n": 3.0,
      "mu_d": 10.0,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@anirbanbasu/pymcp",
      "server_name": "PyMCP",
      "factor": 46,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.8333333333333333,
      "mu_n": 2.6666666666666665,
      "mu_d": 33.666666666666664,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@CelalKhalilov/fruityvice-mcp",
      "server_name": "Fruityvice Nutrition Info Server",
      "factor": 46,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 6.0,
      "mu_d": 64.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@shinzo-labs/gmail-mcp",
      "server_name": "Gmail MCP",
      "factor": 46,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.09375,
      "mu_n": 2.6875,
      "mu_d": 6.46875,
      "n_tools": 64,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 64,
      "tools_count_actual": 64,
      "tools_count_valid": 64,
      "tools_mismatch": false
    },
    {
      "server_id": "@knowall-ai/mcp-neo4j-agent-memory",
      "server_name": "Neo4j Agent Memory Server",
      "factor": 46,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.5555555555555554,
      "mu_n": 2.3333333333333335,
      "mu_d": 17.11111111111111,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@ProfessionalWiki/mediawiki-mcp-server",
      "server_name": "MediaWiki",
      "factor": 46,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.5714285714285716,
      "mu_n": 2.2857142857142856,
      "mu_d": 20.714285714285715,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@jacksmith3888/wuwa-mcp-server",
      "server_name": "鸣潮 MCP Server",
      "factor": 46,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.3333333333333335,
      "mu_d": 69.0,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@zacharyliner1xds/my-sequential-thinking-mcp-v1",
      "server_name": "Sequential Thinking Server",
      "factor": 46,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.2222222222222223,
      "mu_n": 3.0,
      "mu_d": 6.888888888888889,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@PV-Bhat/vibe-check-mcp-server",
      "server_name": "Vibe Check",
      "factor": 46,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.6,
      "mu_n": 3.0,
      "mu_d": 11.4,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@samuelvinay91/testrail-mcp",
      "server_name": "TestRail",
      "factor": 46,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.7,
      "mu_n": 2.2,
      "mu_d": 6.1,
      "n_tools": 10,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 10,
      "tools_count_actual": 10,
      "tools_count_valid": 10,
      "tools_mismatch": false
    },
    {
      "server_id": "@deedubyalabs/neo4j-agent-memory",
      "server_name": "Neo4j Memory",
      "factor": 46,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.5555555555555554,
      "mu_n": 2.3333333333333335,
      "mu_d": 17.11111111111111,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@OEvortex/ddg_search",
      "server_name": "DuckDuckGo & Felo AI Search",
      "factor": 46,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 2.25,
      "mu_d": 24.5,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@PixdataOrg/coderide",
      "server_name": "CodeRide",
      "factor": 46,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.3333333333333333,
      "mu_n": 2.0,
      "mu_d": 39.333333333333336,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@cpretzinger/ai-assistant-simple",
      "server_name": "MemoryForge AI with Redis, PostgreSQL, and Qdrant",
      "factor": 45,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.8571428571428572,
      "mu_n": 3.0952380952380953,
      "mu_d": 8.0,
      "n_tools": 21,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 21,
      "tools_count_actual": 21,
      "tools_count_valid": 21,
      "tools_mismatch": false
    },
    {
      "server_id": "@Knowitall-wiki/mcpollinations",
      "server_name": "MCPollinations",
      "factor": 45,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.2857142857142856,
      "mu_n": 2.5714285714285716,
      "mu_d": 10.142857142857142,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@HarunGuclu/weather_mcp",
      "server_name": "Weather Information Server",
      "factor": 45,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.25,
      "mu_n": 3.75,
      "mu_d": 41.75,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@kennyckk/mcp_hkbus",
      "server_name": "KMB Bus",
      "factor": 45,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.2,
      "mu_n": 4.4,
      "mu_d": 36.4,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@zwldarren/akshare-one-mcp",
      "server_name": "AKShare One MCP Server",
      "factor": 45,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.5555555555555554,
      "mu_n": 3.3333333333333335,
      "mu_d": 10.222222222222221,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@lior-ps/multi-llm-cross-check-mcp-server",
      "server_name": "Multi LLM Cross-Check Server",
      "factor": 45,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 117.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@geobio/reddit-mcp",
      "server_name": "Reddit Browser",
      "factor": 45,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.1666666666666667,
      "mu_n": 3.1666666666666665,
      "mu_d": 39.833333333333336,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@alex-llm/attack-mcp-server",
      "server_name": "attAck MCP Server",
      "factor": 45,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.6666666666666665,
      "mu_d": 39.666666666666664,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@flutterninja9/better-fetch",
      "server_name": "Better Fetch",
      "factor": 45,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 4.5,
      "mu_n": 3.0,
      "mu_d": 11.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@supabase-community/supabase-mcp",
      "server_name": "Supabase MCP Server",
      "factor": 44,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.9411764705882353,
      "mu_n": 2.588235294117647,
      "mu_d": 24.705882352941178,
      "n_tools": 17,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 17,
      "tools_count_actual": 17,
      "tools_count_valid": 17,
      "tools_mismatch": false
    },
    {
      "server_id": "@zeyynepkaraduman/memory-palace-mcp",
      "server_name": "Memory Palace",
      "factor": 44,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.6666666666666665,
      "mu_n": 2.888888888888889,
      "mu_d": 7.888888888888889,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@synthetic-ci/vibe-marketing",
      "server_name": "Vibe Marketing MCP (HyperFeed.ai)",
      "factor": 44,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.7,
      "mu_n": 4.2,
      "mu_d": 14.8,
      "n_tools": 10,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 10,
      "tools_count_actual": 10,
      "tools_count_valid": 10,
      "tools_mismatch": false
    },
    {
      "server_id": "@ardyfeb/package-registry-mcp",
      "server_name": "Package Registry Server",
      "factor": 44,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.6153846153846154,
      "mu_n": 5.384615384615385,
      "mu_d": 8.307692307692308,
      "n_tools": 13,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 13,
      "tools_count_actual": 13,
      "tools_count_valid": 13,
      "tools_mismatch": false
    },
    {
      "server_id": "@kaantenik/dictionary-mcp",
      "server_name": "Elevator Pitch",
      "factor": 44,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 3.5,
      "mu_d": 19.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@effytech/freshdesk_mcp",
      "server_name": "Freshdesk Integration Server",
      "factor": 44,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.4310344827586208,
      "mu_n": 2.9310344827586206,
      "mu_d": 8.120689655172415,
      "n_tools": 58,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 59,
      "tools_count_actual": 59,
      "tools_count_valid": 58,
      "tools_mismatch": false
    },
    {
      "server_id": "@berkanttozbay/mcplatest",
      "server_name": "mcpLatest Server",
      "factor": 44,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.0,
      "mu_d": 78.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@rishipradeep-think41/gsuite-mcp",
      "server_name": "Google Workspace Server",
      "factor": 44,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.625,
      "mu_n": 2.0,
      "mu_d": 5.75,
      "n_tools": 8,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 8,
      "tools_count_actual": 8,
      "tools_count_valid": 8,
      "tools_mismatch": false
    },
    {
      "server_id": "@mario-andreschak/mcp-abap-abap-adt-api",
      "server_name": "ABAP-ADT-API MCP-Server",
      "factor": 44,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.111111111111111,
      "mu_n": 2.074074074074074,
      "mu_d": 5.0,
      "n_tools": 27,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 27,
      "tools_count_actual": 27,
      "tools_count_valid": 27,
      "tools_mismatch": false
    },
    {
      "server_id": "@Liam8/free-coin-price-mcp",
      "server_name": "Free Crypto Coin Data",
      "factor": 44,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.1666666666666665,
      "mu_n": 4.166666666666667,
      "mu_d": 16.166666666666668,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@shreyaskarnik/huggingface-mcp-server",
      "server_name": "Hugging Face MCP Server",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.3,
      "mu_n": 3.3,
      "mu_d": 8.1,
      "n_tools": 10,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 10,
      "tools_count_actual": 10,
      "tools_count_valid": 10,
      "tools_mismatch": false
    },
    {
      "server_id": "@HugoGuedesipvc/ao-generativeai-cp3-smithery",
      "server_name": "AO Generative AI CP3 Smithery Server",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.6666666666666666,
      "mu_n": 4.0,
      "mu_d": 41.333333333333336,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@samihalawa/remote-shell-terminal-mcp",
      "server_name": "Remote Shell Server",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 2.0,
      "mu_d": 30.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@maxvint/mcp-crypto-research",
      "server_name": "Crypto Research Server",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.6,
      "mu_n": 4.0,
      "mu_d": 9.2,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@yywz1999/gdb-mcp-server",
      "server_name": "GDB MCP 服务器",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.625,
      "mu_n": 4.1875,
      "mu_d": 5.125,
      "n_tools": 16,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 16,
      "tools_count_actual": 16,
      "tools_count_valid": 16,
      "tools_mismatch": false
    },
    {
      "server_id": "@1595901624/crypto-mcp",
      "server_name": "Crypto_MCP",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.4285714285714284,
      "mu_n": 2.142857142857143,
      "mu_d": 5.785714285714286,
      "n_tools": 14,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 14,
      "tools_count_actual": 14,
      "tools_count_valid": 14,
      "tools_mismatch": false
    },
    {
      "server_id": "@smithery/toolbox",
      "server_name": "Toolbox",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 2.0,
      "mu_d": 40.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@ForceConstant/lyrical_mcp",
      "server_name": "Lyrical MCP",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.5,
      "mu_n": 2.75,
      "mu_d": 70.25,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@florentine-ai/mcp",
      "server_name": "Florentine.ai - Talk to your MongoDB data",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.5,
      "mu_n": 4.5,
      "mu_d": 61.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@hetaoBackend/mcp-github-trending",
      "server_name": "GitHub Trending",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 7.5,
      "mu_d": 5.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@hetaoBackend/github-trending-mcp-server",
      "server_name": "GitHub Trending",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 7.5,
      "mu_d": 5.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@kwen1510/nltk-map",
      "server_name": "NLTK Model Context Protocol Server",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 4.0,
      "mu_d": 33.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ismailcan0/publicholidaysmcp",
      "server_name": "Public Holidays Service",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 4.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@DarkNoah/feishu-mcp",
      "server_name": "飞书多维表格",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.875,
      "mu_n": 2.25,
      "mu_d": 8.625,
      "n_tools": 8,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 8,
      "tools_count_actual": 8,
      "tools_count_valid": 8,
      "tools_mismatch": false
    },
    {
      "server_id": "@Decodo/decodo-mcp-server",
      "server_name": "Decodo MCP Server",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 3.2,
      "mu_d": 8.6,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@ilil1/excel-mcp-server",
      "server_name": "Excel MCP Server",
      "factor": 43,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 2.0,
      "mu_d": 28.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@geobio/wikipedia-mcp",
      "server_name": "Wikipedia Integration Server",
      "factor": 42,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.8888888888888888,
      "mu_n": 3.2222222222222223,
      "mu_d": 10.444444444444445,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@vines90/mcp-prompt-server",
      "server_name": "Prompt Server",
      "factor": 42,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.272727272727273,
      "mu_n": 2.8181818181818183,
      "mu_d": 4.7272727272727275,
      "n_tools": 11,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 11,
      "tools_count_actual": 11,
      "tools_count_valid": 11,
      "tools_mismatch": false
    },
    {
      "server_id": "@8enSmith/mcp-open-library",
      "server_name": "Open Library MCP Server",
      "factor": 42,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 3.6666666666666665,
      "mu_d": 19.833333333333332,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@1282saa/news_sum",
      "server_name": "Google Workshop MCP Server",
      "factor": 42,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.25,
      "mu_d": 37.25,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@yusaaztrk/car-price-mcp-main",
      "server_name": "Car Price Server",
      "factor": 42,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.6666666666666666,
      "mu_n": 4.0,
      "mu_d": 50.333333333333336,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@Rudra-ravi/wikipedia-mcp",
      "server_name": "Wikipedia Information Server",
      "factor": 42,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.8888888888888888,
      "mu_n": 3.2222222222222223,
      "mu_d": 10.444444444444445,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@smithery-ai/slack",
      "server_name": "Slack",
      "factor": 42,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.142857142857143,
      "mu_n": 3.5714285714285716,
      "mu_d": 9.428571428571429,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@kkoppenhaver/minecraft-mcp-server",
      "server_name": "Minecraft Bot Server",
      "factor": 42,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.875,
      "mu_n": 2.3125,
      "mu_d": 7.25,
      "n_tools": 16,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 16,
      "tools_count_actual": 16,
      "tools_count_valid": 16,
      "tools_mismatch": false
    },
    {
      "server_id": "@rishipradeep-think41/google-drive-mcp",
      "server_name": "Google Drive",
      "factor": 42,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.1136363636363635,
      "mu_n": 3.272727272727273,
      "mu_d": 7.045454545454546,
      "n_tools": 44,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 44,
      "tools_count_actual": 44,
      "tools_count_valid": 44,
      "tools_mismatch": false
    },
    {
      "server_id": "@sankygawas/mcp-server-reddit",
      "server_name": "Reddit Content Access Server",
      "factor": 42,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 4.375,
      "mu_d": 6.5,
      "n_tools": 8,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 8,
      "tools_count_actual": 8,
      "tools_count_valid": 8,
      "tools_mismatch": false
    },
    {
      "server_id": "@AudienseCo/mcp-audiense-di-linkedin",
      "server_name": "LinkedIn Digital Intelligence Server",
      "factor": 41,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.1,
      "mu_n": 5.1,
      "mu_d": 11.2,
      "n_tools": 10,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 10,
      "tools_count_actual": 10,
      "tools_count_valid": 10,
      "tools_mismatch": false
    },
    {
      "server_id": "@ErgodicLabs/twotruthsandatwist",
      "server_name": "Two Truths and a Twist",
      "factor": 41,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.1666666666666665,
      "mu_n": 2.3333333333333335,
      "mu_d": 13.833333333333334,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@javilujann/timemcp",
      "server_name": "Time Server",
      "factor": 41,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.5,
      "mu_n": 2.0,
      "mu_d": 77.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@cloudflare/playwright-mcp",
      "server_name": "Cloudflare Playwright",
      "factor": 41,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.25,
      "mu_n": 2.75,
      "mu_d": 6.791666666666667,
      "n_tools": 24,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 24,
      "tools_count_actual": 24,
      "tools_count_valid": 24,
      "tools_mismatch": false
    },
    {
      "server_id": "@ndchikin/reference-mcp",
      "server_name": "CiteAssist MCP",
      "factor": 41,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 5.0,
      "mu_d": 23.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@mem0ai/mem0-memory-mcp",
      "server_name": "Memory Tool",
      "factor": 41,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 24.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@Hott-J/coingecko-mcp-server",
      "server_name": "CoinGecko MCP Server",
      "factor": 41,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 4.5,
      "mu_d": 11.75,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@SleepyRabbit/playwright-mcp",
      "server_name": "Playwright Browser Automation Server",
      "factor": 41,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.3043478260869565,
      "mu_n": 2.739130434782609,
      "mu_d": 6.739130434782608,
      "n_tools": 23,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 23,
      "tools_count_actual": 23,
      "tools_count_valid": 23,
      "tools_mismatch": false
    },
    {
      "server_id": "@m2rads/e2e-mcp",
      "server_name": "End to End Testing Server",
      "factor": 41,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.3125,
      "mu_n": 2.625,
      "mu_d": 9.5,
      "n_tools": 16,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 16,
      "tools_count_actual": 16,
      "tools_count_valid": 16,
      "tools_mismatch": false
    },
    {
      "server_id": "@vinhphamai23/playwright-mcp",
      "server_name": "Playwright Browser Automation Server",
      "factor": 41,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.3043478260869565,
      "mu_n": 2.739130434782609,
      "mu_d": 6.739130434782608,
      "n_tools": 23,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 23,
      "tools_count_actual": 23,
      "tools_count_valid": 23,
      "tools_mismatch": false
    },
    {
      "server_id": "@alan5543/calculator-mcp",
      "server_name": "Advanced Calculator Server",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.588235294117647,
      "mu_n": 1.8235294117647058,
      "mu_d": 7.647058823529412,
      "n_tools": 17,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 17,
      "tools_count_actual": 17,
      "tools_count_valid": 17,
      "tools_mismatch": false
    },
    {
      "server_id": "@nickclyde/duckduckgo-mcp-server",
      "server_name": "DuckDuckGo Search Server",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 1.5,
      "mu_d": 41.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@daheepk/arxiv-paper-mcp",
      "server_name": "arXiv Research Assistant",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.75,
      "mu_n": 3.75,
      "mu_d": 17.25,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@sellisd/mcp-units",
      "server_name": "Cooking Units Converter",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 2.0,
      "mu_d": 13.333333333333334,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@YingHe-1/yhfirstmcpserver",
      "server_name": "Desktop TXT File Manager",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.75,
      "mu_n": 4.5,
      "mu_d": 29.25,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@Nekzus/npm-sentinel-mcp",
      "server_name": "NPM Sentinel MCP",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.105263157894737,
      "mu_n": 2.6315789473684212,
      "mu_d": 8.052631578947368,
      "n_tools": 19,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 19,
      "tools_count_actual": 19,
      "tools_count_valid": 19,
      "tools_mismatch": false
    },
    {
      "server_id": "@Hang-InThere/mcp",
      "server_name": "Hang-InThere MCP Server",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.5,
      "mu_d": 39.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@kdkiss/mcp-stepstone",
      "server_name": "Stepstone Job Listings Fetcher",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 2.5,
      "mu_d": 11.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@BarkApp/pote-mcp",
      "server_name": "Pote",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 4.0,
      "mu_d": 19.75,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@edibertoalves/mcp_ibge",
      "server_name": "IBGE Municipality Listing Server",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 6.4,
      "mu_d": 16.8,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@jun85664396/pump-fun-data-mcp",
      "server_name": "Pump.fun Data Fetch Tool",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 3.3333333333333335,
      "mu_d": 5.333333333333333,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@linyimin0812/project-ingest-mcp",
      "server_name": "Project Ingest MCP Server",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.3333333333333333,
      "mu_n": 2.0,
      "mu_d": 36.333333333333336,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@isdaniel/mcp_weather_server",
      "server_name": "Weather MCP Server",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.6666666666666667,
      "mu_n": 3.6666666666666665,
      "mu_d": 19.0,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@daniellopez-2/youtube-download",
      "server_name": "yt-dlp Video and Audio Downloader",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.6,
      "mu_n": 2.8,
      "mu_d": 18.6,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@DeepLcom/deepl-mcp-server",
      "server_name": "DeepL Translation Server",
      "factor": 40,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.8333333333333333,
      "mu_n": 3.6666666666666665,
      "mu_d": 9.5,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@flrngel/mcp-painter",
      "server_name": "Drawing Tool for AI Assistants",
      "factor": 39,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.75,
      "mu_n": 3.75,
      "mu_d": 12.75,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@EthanHenrickson/math-mcp",
      "server_name": "Math-MCP",
      "factor": 39,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.2272727272727273,
      "mu_n": 1.5454545454545454,
      "mu_d": 9.0,
      "n_tools": 22,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 22,
      "tools_count_actual": 22,
      "tools_count_valid": 22,
      "tools_mismatch": false
    },
    {
      "server_id": "@terryso/mcp-pinterest",
      "server_name": "Pinterest MCP Server",
      "factor": 39,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.3333333333333335,
      "mu_n": 4.333333333333333,
      "mu_d": 7.0,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@emineturan/books",
      "server_name": "Books Server",
      "factor": 39,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.3333333333333335,
      "mu_d": 38.333333333333336,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@smithery-ai/google-maps",
      "server_name": "Google Maps",
      "factor": 39,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.142857142857143,
      "mu_d": 6.857142857142857,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@big-omega/mem0-mcp",
      "server_name": "Mem0 Memory Server",
      "factor": 39,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.25,
      "mu_n": 2.75,
      "mu_d": 26.0,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@Shengwenhao-manbo/weather1",
      "server_name": "Weather",
      "factor": 39,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 3.0,
      "mu_d": 25.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@meowhuman/weather",
      "server_name": "Weather",
      "factor": 39,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 3.0,
      "mu_d": 27.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@JackKuo666/weather-mcp-server",
      "server_name": "Weather MCP Server",
      "factor": 39,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 3.0,
      "mu_d": 27.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@Reculi/weather-mcp-server",
      "server_name": "Weather Query Server",
      "factor": 39,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 3.0,
      "mu_d": 27.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@QuantML-Github/alpha-vantage-mcp",
      "server_name": "Alpha Vantage MCP Server",
      "factor": 39,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.2,
      "mu_n": 3.8,
      "mu_d": 6.6,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@ddkang1/mcp-think-tool",
      "server_name": "Think Tool Server",
      "factor": 38,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.25,
      "mu_n": 3.25,
      "mu_d": 42.25,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@arjunkmrm/perplexity-search",
      "server_name": "Perplexity Search",
      "factor": 38,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 1.0,
      "mu_d": 34.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@just-record/mcpserver-test",
      "server_name": "MCP Server Test",
      "factor": 38,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 3.0,
      "mu_d": 25.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@Yaxin9Luo/openai_agent_library_mcp",
      "server_name": "OpenAI Agent Library",
      "factor": 38,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.8181818181818182,
      "mu_n": 2.8181818181818183,
      "mu_d": 15.363636363636363,
      "n_tools": 11,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 11,
      "tools_count_actual": 11,
      "tools_count_valid": 11,
      "tools_mismatch": false
    },
    {
      "server_id": "@yusaaztrk/movie-mcp-main",
      "server_name": "Movie Information Server",
      "factor": 38,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 49.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@zhouxubin/myfirstmcp",
      "server_name": "MyFirstMCP",
      "factor": 38,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 1.0,
      "mu_d": 30.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@Streen9/azure-mcp",
      "server_name": "Azure MCP",
      "factor": 38,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.4444444444444444,
      "mu_n": 3.5555555555555554,
      "mu_d": 6.333333333333333,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@hydavinci/weather_mcp",
      "server_name": "Region Weather",
      "factor": 38,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 45.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@smithery-ai/fetch",
      "server_name": "Fetch",
      "factor": 38,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 2.3333333333333335,
      "mu_d": 15.333333333333334,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@fnf-deepHeading/mcp-snowflake-reader",
      "server_name": "Snowflake Reader",
      "factor": 38,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 1.0,
      "mu_d": 58.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@seekeasy/seekeasy",
      "server_name": "Seekeasy MCP Server",
      "factor": 38,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.0,
      "mu_d": 39.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@nqdhocai/test-mcp-py",
      "server_name": "Test Server",
      "factor": 37,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.6666666666666667,
      "mu_n": 2.8333333333333335,
      "mu_d": 7.5,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@musabz360/weather360",
      "server_name": "Weather360 Server",
      "factor": 37,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 16.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@mauricio-cantu/brasil-api-mcp-server",
      "server_name": "BrasilAPI MCP Server",
      "factor": 37,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.8333333333333334,
      "mu_n": 4.333333333333333,
      "mu_d": 13.166666666666666,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@barlanyado/mcp-server-test1",
      "server_name": "MCP Server Test",
      "factor": 37,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.0,
      "mu_d": 36.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@AIM-Intelligence/aim-mcp",
      "server_name": "AIM Guard",
      "factor": 37,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 4.0,
      "mu_d": 7.333333333333333,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@yokingma/time-mcp",
      "server_name": "Time MCP Server",
      "factor": 36,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 2.3333333333333335,
      "mu_d": 10.333333333333334,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@cfdude/super-shell-mcp",
      "server_name": "Super Shell",
      "factor": 36,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.2222222222222223,
      "mu_n": 2.888888888888889,
      "mu_d": 7.0,
      "n_tools": 9,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 9,
      "tools_count_actual": 9,
      "tools_count_valid": 9,
      "tools_mismatch": false
    },
    {
      "server_id": "@marioluciofjr/mapas_mentais_mcp",
      "server_name": "Mapas Mentais Server",
      "factor": 36,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.1666666666666667,
      "mu_n": 2.5,
      "mu_d": 13.5,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@myrve/mcp-fruit",
      "server_name": "Fruit Data Server",
      "factor": 36,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 4.0,
      "mu_d": 24.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@jobsonlook/xhs-mcp",
      "server_name": "小红书 MCP 服务  xiaohongshu",
      "factor": 36,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.8333333333333334,
      "mu_n": 2.3333333333333335,
      "mu_d": 19.166666666666668,
      "n_tools": 6,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 6,
      "tools_count_actual": 6,
      "tools_count_valid": 6,
      "tools_mismatch": false
    },
    {
      "server_id": "@pwh-pwh/cal-mcp",
      "server_name": "Cal Server",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.75,
      "mu_n": 2.75,
      "mu_d": 21.25,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@MetehanGZL/pokemcp",
      "server_name": "Pokémon Information Server",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.142857142857143,
      "mu_d": 8.714285714285714,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@ly729027676/mcp-serve-testweather",
      "server_name": "mcp服务",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 1.5,
      "mu_d": 22.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@mfukushim/map-traveler-mcp",
      "server_name": "Virtual Traveling Bot",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.5,
      "mu_n": 3.75,
      "mu_d": 12.125,
      "n_tools": 8,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 8,
      "tools_count_actual": 8,
      "tools_count_valid": 8,
      "tools_mismatch": false
    },
    {
      "server_id": "@hereisnitish/mcp-server",
      "server_name": "MCP Server",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 11.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ebubekirkarakurt/mcp-word",
      "server_name": "MCP-WORD Server",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@emineturan/weather",
      "server_name": "Weather Service",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@mirackoglu/weather-mcp-2",
      "server_name": "Weather Information Server",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@musabz360/weather_temperature",
      "server_name": "360 Weather MCP",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@MehmetFatihAktas/weather-mcp",
      "server_name": "Weather Information Server",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@Pembenaz/weather-forecast-mcp-main",
      "server_name": "Weather Forecast Service",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@hamzaefecarikci/weather-forecast-mcp",
      "server_name": "Weather Forecast Service",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@cihantasdemiir/mcp-word",
      "server_name": "MCP-WORD Server",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@yurthankiyak/weather-forecast-mcp55",
      "server_name": "Weather Forecast Service",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ismailbl72/weather-forecast-mcp-main12",
      "server_name": "Weather Forecast Service",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@abugrakskn/weather-forecast-mcp",
      "server_name": "Weather Forecast Service",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@zehranurugurr/weather_mcp",
      "server_name": "Weather Information Server",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@emineturan/weatherr",
      "server_name": "weatherr",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@eminaltan6809/weather-forecast-mcp",
      "server_name": "Weather Forecast",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@myrve/weather-forecast-mcp-mevy",
      "server_name": "Weather Forecast Server",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ErenYlskn/weather_app",
      "server_name": "Weather App Server",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@databutton/databutton-mcp",
      "server_name": "Databutton",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 3.0,
      "mu_d": 3.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@fahadBSTech/mcp-gmail-sender",
      "server_name": "Email Sender Server",
      "factor": 35,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 2.0,
      "mu_d": 6.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@PhillipRt/think-mcp-server",
      "server_name": "Think Tool Server",
      "factor": 34,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 1.0,
      "mu_d": 40.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@marcopesani/think-mcp-server",
      "server_name": "Think MCP Server",
      "factor": 34,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 1.0,
      "mu_d": 40.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@devlimelabs/lulu-print-mcp",
      "server_name": "Lulu Print",
      "factor": 34,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 3.5,
      "mu_d": 9.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@BlirBatuhan/steam-stats-mcp",
      "server_name": "Steam Statistics",
      "factor": 34,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.5,
      "mu_n": 3.75,
      "mu_d": 18.75,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@alexhamidi/addtwo",
      "server_name": "Linkd Model Context Protocol Server",
      "factor": 34,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 3.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@iamwavecut/mcp-think",
      "server_name": "Think Tool",
      "factor": 33,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.25,
      "mu_n": 3.25,
      "mu_d": 23.5,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@dazeb/markdown-downloader",
      "server_name": "Markdown Downloader",
      "factor": 33,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.2,
      "mu_d": 7.8,
      "n_tools": 5,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 5,
      "tools_count_actual": 5,
      "tools_count_valid": 5,
      "tools_mismatch": false
    },
    {
      "server_id": "@fisher1006/time-mcp-4",
      "server_name": "Time Server",
      "factor": 33,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 2.5,
      "mu_d": 6.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@halismertkir/game-trends-mcp",
      "server_name": "Game Trends",
      "factor": 33,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.0,
      "mu_n": 5.285714285714286,
      "mu_d": 13.142857142857142,
      "n_tools": 7,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 7,
      "tools_count_actual": 7,
      "tools_count_valid": 7,
      "tools_mismatch": false
    },
    {
      "server_id": "@ichewm/mcp-add-test",
      "server_name": "Add Test",
      "factor": 33,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 4.0,
      "mu_d": 4.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ahmetcvlk/nationality-mcp",
      "server_name": "Nationality Detection Service",
      "factor": 33,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 4.0,
      "mu_d": 17.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@lieyanqzu/ygocdb-mcp",
      "server_name": "YGO Chinese Card Database - 百鸽(ygocdb.com)",
      "factor": 33,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.0,
      "mu_d": 15.0,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@Huramkin/price-mcp-server",
      "server_name": "Price MCP Server",
      "factor": 33,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 3.5,
      "mu_d": 8.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@shenpeiheng/mcp-server-chinarailway",
      "server_name": "12306 MCP Server",
      "factor": 33,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 3.0,
      "mu_n": 1.0,
      "mu_d": 6.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@AITutor3/calculator-mcp",
      "server_name": "Calculator",
      "factor": 32,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 1.0,
      "mu_d": 5.0,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@SpaceStation09/newsfeed-mcp",
      "server_name": "News Feed Server",
      "factor": 32,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.0,
      "mu_n": 2.0,
      "mu_d": 45.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@ShresthaAnkit/mcpserver",
      "server_name": "MCP Server",
      "factor": 32,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 1.5,
      "mu_d": 8.25,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@NSP-MO/mcp-client-chatbot",
      "server_name": "MCP Client Chatbot",
      "factor": 32,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 2.0,
      "mu_d": 8.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@thedaviddias/mcp-llms-txt-explorer",
      "server_name": "LLMS.txt Explorer",
      "factor": 32,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 2.5,
      "mu_d": 8.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@alan5543/mcp-test",
      "server_name": "Simple MCP Server",
      "factor": 32,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 2.0,
      "mu_d": 8.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@szypetike/domain-search-server",
      "server_name": "Domain Search - No API key required.",
      "factor": 32,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 4.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@SmartManoj/telegram-bot-mcp",
      "server_name": "Telegram Bot MCP",
      "factor": 32,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 4.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@pinion05/supabase-mcp-lite",
      "server_name": "supabase-mcp-lite",
      "factor": 32,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.75,
      "mu_d": 9.0,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@NaveenBandarage/poke-mcp",
      "server_name": "Pokémcp",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.75,
      "mu_n": 3.75,
      "mu_d": 6.25,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@Busra-ozer/book-search-mcp",
      "server_name": "Book Search Server",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.0,
      "mu_d": 16.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@glassBead-tc/weather-mcp",
      "server_name": "Weather Server",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.25,
      "mu_n": 1.75,
      "mu_d": 8.25,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@crakcode/test_mcp_2",
      "server_name": "Weather Information Server",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.25,
      "mu_n": 1.75,
      "mu_d": 8.25,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@ceydasimsekk/book_mcp",
      "server_name": "Book MCP Server",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.0,
      "mu_d": 16.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ceydasimsekk/open_book_mcp",
      "server_name": "Open Book",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.0,
      "mu_d": 16.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@EmirHth/weather-forecast-mcp1",
      "server_name": "Call For Papers",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 2.0,
      "mu_d": 7.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ismailbl72/call-for-papers-mcp",
      "server_name": "ConferenceSearcher",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 2.0,
      "mu_d": 7.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@mcp-examples/weather",
      "server_name": "Weather",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 3.0,
      "mu_d": 6.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@adarshem/mcp-server-learn",
      "server_name": "Weather Server",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 3.0,
      "mu_d": 6.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@EmirHth/weather-forecast-mcp",
      "server_name": "Call For Papers",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 2.0,
      "mu_d": 7.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@kim-geon-admin/mcp",
      "server_name": "Model Context Protocol Server",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 2.5,
      "mu_d": 8.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@kentstudy0922/weather-mcp",
      "server_name": "Weather MCP Server",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 3.0,
      "mu_d": 6.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@MuratYurtseven/recipemcp",
      "server_name": "Recipe Assistant Server",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.0,
      "mu_d": 14.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@makingendless/endless-mcp",
      "server_name": "Endless",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.5,
      "mu_n": 3.0,
      "mu_d": 6.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@alperenkocyigit/call-for-papers-mcp",
      "server_name": "Call For Papers MCP",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 2.0,
      "mu_d": 7.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@leegentle/skincare-mcp",
      "server_name": "Skincare",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 4.0,
      "mu_d": 12.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ramadasmr/networkcalc-mcp",
      "server_name": "NetworkCalc",
      "factor": 31,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.5,
      "mu_d": 7.75,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@manimohans/verge-news-mcp",
      "server_name": "The Verge News Server",
      "factor": 30,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.6666666666666666,
      "mu_n": 3.3333333333333335,
      "mu_d": 10.666666666666666,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@aurora-is-near/doc-aurora-dev",
      "server_name": "Aurora Documentation",
      "factor": 30,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.3333333333333335,
      "mu_d": 8.333333333333334,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@hugeicons/mcp-server",
      "server_name": "Hugeicons MCP Server",
      "factor": 30,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.6666666666666666,
      "mu_n": 2.3333333333333335,
      "mu_d": 14.333333333333334,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@charles-adedotun/Lilith-Shell",
      "server_name": "Lilith Shell",
      "factor": 30,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 2.0,
      "mu_d": 4.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@hcatakli/medicine-mcp",
      "server_name": "Medicine MCP Server",
      "factor": 30,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 4.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@Huramkin/add_mcp",
      "server_name": "Add Numbers Server",
      "factor": 30,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 2.0,
      "mu_d": 5.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@IlaydaBayrak/simple-mcp",
      "server_name": "Simple MCP Server",
      "factor": 30,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ceydasimsekk/simple-mcp",
      "server_name": "Simple MCP Server",
      "factor": 30,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@hcatakli/disney-app",
      "server_name": "Disney App MCP Server",
      "factor": 30,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 3.0,
      "mu_d": 12.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@Alex-Smith-1234/map_mcp",
      "server_name": "Map MCP Server",
      "factor": 30,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 16.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@bombe89/mcp-servers-test2",
      "server_name": "Math Server",
      "factor": 29,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 1.0,
      "mu_d": 4.0,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@ubn-dev/mcp_calculator",
      "server_name": "Calculator Service",
      "factor": 29,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 1.0,
      "mu_d": 6.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@swaroopkasaraneni/math-mcp-server",
      "server_name": "Math Operations Server",
      "factor": 29,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 1.0,
      "mu_d": 4.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@JonaFly/rednote-mcp",
      "server_name": "RedNote Content Access Server",
      "factor": 29,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.25,
      "mu_d": 5.0,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@gandli/yanyue-mcp",
      "server_name": "Yanyue Cigarette Data",
      "factor": 29,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 4.0,
      "mu_d": 7.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@RusianHu/weibo_hotsearch_mcp",
      "server_name": "Weibo Hot Search Service - 获取微博热搜",
      "factor": 29,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.0,
      "mu_n": 3.0,
      "mu_d": 28.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@nisa439/weather-calculator-mcp",
      "server_name": "Weather Calculator",
      "factor": 28,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 5.333333333333333,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@imlewc/elasticsearch7-mcp-server",
      "server_name": "Elasticsearch 7.x MCP Server",
      "factor": 28,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.3333333333333335,
      "mu_d": 3.6666666666666665,
      "n_tools": 3,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 3,
      "tools_count_actual": 3,
      "tools_count_valid": 3,
      "tools_mismatch": false
    },
    {
      "server_id": "@iremert/movie-recommender-mcp",
      "server_name": "Movie Recommender",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 10.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ceydasimsekk/dictionarymcp",
      "server_name": "Dictionary Server",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@lorenzwoehr/lorenzwoehr-mcp",
      "server_name": "Lorenz Woehr Portfolio",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.25,
      "mu_n": 2.5,
      "mu_d": 8.75,
      "n_tools": 4,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 4,
      "tools_count_actual": 4,
      "tools_count_valid": 4,
      "tools_mismatch": false
    },
    {
      "server_id": "@meren41/s-navmobil",
      "server_name": "Manga Translator",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.0,
      "mu_n": 4.0,
      "mu_d": 16.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@jbak36/mcp_test_jbak",
      "server_name": "MCP Test Server",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 1.0,
      "mu_d": 3.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ismailbl72/mcp-directory",
      "server_name": "MCP Directory Server",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ivan-saorin/mcp-expr-lang",
      "server_name": "Expression Evaluation Server",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 2.0,
      "mu_n": 1.0,
      "mu_d": 3.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@EminUstun/mcp-server",
      "server_name": "MCP Server",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@yusaaztrk/dictionary-mcp-main-for-mobile-app",
      "server_name": "Dictionary Service",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@emineturan/dictionary",
      "server_name": "Dictionary",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@sametbassoy/mcp-server",
      "server_name": "MCP Server",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@hcatakli/dictionary-mcp",
      "server_name": "Dictionary Service",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@emro624/dictionary-mcp-main",
      "server_name": "Dictionary MCP Server",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@RabiaDogan41/mobil_challenge",
      "server_name": "Mobile Challenge Server",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@myrve/dictionary-mcp",
      "server_name": "Dictionary Server",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 10.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@AITutor3/weather-mcp11",
      "server_name": "Weather Information Server",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 10.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@Pembenaz/dictionary-mcp-main1",
      "server_name": "Dictionary MCP Server",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@akifsilan/dictionary-mcp-main",
      "server_name": "Dictionary MCP Server",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@MuratYurtseven/mcp",
      "server_name": "MCP Python Server",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@dravidsajinraj-iex/ai-diagram-generator-mcp",
      "server_name": "Eraser Diagram Generator",
      "factor": 27,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 10.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@datawiz168/mcp-service-snowflake",
      "server_name": "Snowflake Database Access Server",
      "factor": 26,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 7.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@esmakymkci/yeni_detect_lang_mcp",
      "server_name": "Language Detection Server",
      "factor": 26,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 1.0,
      "mu_d": 13.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@advanceteam168/myfirstmcpserver",
      "server_name": "First MCP Server",
      "factor": 26,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 2.0,
      "mu_d": 8.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@githejie/mcp-server-calculator",
      "server_name": "Calculator",
      "factor": 25,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 1.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@geobio/mcp-server-calculator",
      "server_name": "Calculator Server",
      "factor": 25,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 1.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@jingzhouzhao/mcp-ailab-demo",
      "server_name": "AI Lab MCP Server",
      "factor": 25,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.5,
      "mu_n": 2.5,
      "mu_d": 7.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@DocumentLess/mytime",
      "server_name": "MyTime",
      "factor": 25,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.5,
      "mu_n": 2.5,
      "mu_d": 5.5,
      "n_tools": 2,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 2,
      "tools_count_actual": 2,
      "tools_count_valid": 2,
      "tools_mismatch": false
    },
    {
      "server_id": "@dongri/mcp-server-lgtm",
      "server_name": "LGTM",
      "factor": 25,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.0,
      "mu_n": 4.0,
      "mu_d": 12.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@ismailcan0/catfactsmcp",
      "server_name": "Cat Facts Service",
      "factor": 24,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.0,
      "mu_n": 2.0,
      "mu_d": 17.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@zehranurugurr/film_mcp2",
      "server_name": "Film Information Server",
      "factor": 24,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.0,
      "mu_n": 3.0,
      "mu_d": 12.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@figstra/usewebhook-mcp",
      "server_name": "UseWebhook",
      "factor": 22,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.0,
      "mu_n": 3.0,
      "mu_d": 9.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@PawNzZi/aidaily",
      "server_name": "AIDaily",
      "factor": 22,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.0,
      "mu_n": 4.0,
      "mu_d": 5.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@albertlieyingadrian/example-mcp",
      "server_name": "Example MCP Server",
      "factor": 22,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 1.0,
      "mu_n": 1.0,
      "mu_d": 4.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@AITutor3/weather-mcp",
      "server_name": "Weather Information Server",
      "factor": 21,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.0,
      "mu_n": 2.0,
      "mu_d": 10.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    },
    {
      "server_id": "@AITutor3/weather-mcp2",
      "server_name": "Weather Information Server",
      "factor": 21,
      "level": "Simple",
      "threshold": 50,
      "mu_p": 0.0,
      "mu_n": 2.0,
      "mu_d": 10.0,
      "n_tools": 1,
      "has_output_schema": false,
      "tokenizer": {
        "backend": "vllm",
        "model": "meta-llama/Meta-Llama-3.1-8B",
        "factory": "get_tokenizer"
      },
      "tools_count_reported": 1,
      "tools_count_actual": 1,
      "tools_count_valid": 1,
      "tools_mismatch": false
    }
  ],
  "skipped_servers": [
    {
      "server_id": "@microsoft/playwright-mcp",
      "server_name": "Playwright Automation",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@JackKuo666/pubmed-mcp-server",
      "server_name": "PubMed MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@mirinda-cmd/reference-servers-check",
      "server_name": "Reference Servers",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@executeautomation/playwright-mcp-server",
      "server_name": "Playwright",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@GongRzhe/Office-PowerPoint-MCP-Server",
      "server_name": "PowerPoint Manipulation Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@smithery-ai/puppeteer",
      "server_name": "Puppeteer Browser",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@zehranurugurr/film_mcp1",
      "server_name": "Film Information Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@geobio/pubmed-mcp-server",
      "server_name": "PubMed Article Search and Analysis Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@CartographAI/atlas-docs-mcp",
      "server_name": "Atlas Docs",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "iterm-mcp",
      "server_name": "iTerm",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@pjookim/mcp-visit-korea",
      "server_name": "Korea Tour",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@HarunGuclu/bible-mcp",
      "server_name": "Bible Verse Access Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@fiebsy/shotclock",
      "server_name": "Shotclock",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@ErickWendel/erickwendel-contributions-mcp",
      "server_name": "Erick Wendel Contributions",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@asifdotpy/mcp-weather-server",
      "server_name": "Weather MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@JackKuo666/pubchem-mcp-server",
      "server_name": "PubChem MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@jiqingci/google",
      "server_name": "Google Scholar Search Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@datafe/quick-chart-mcp",
      "server_name": "Quick Chart Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@chapin666/office-powerpoint-mcp-server",
      "server_name": "PowerPoint Manipulation Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@flynnhou/deep-dive-mcp",
      "server_name": "Deep Dive MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@smithery-ai/filesystem",
      "server_name": "Filesystem MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@turkyden/weather",
      "server_name": "Weather",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@DeadWaveWave/google-scholar-mcp-server",
      "server_name": "Google Scholar Search Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "mcp-server-bigquery",
      "server_name": "BigQuery Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@wdm0006/mutmut-mcp",
      "server_name": "Mutation Testing Manager",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@gongrzhe/server-gmail-autoauth-mcp",
      "server_name": "Gmail AutoAuth",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@ilkerAdanur/mcp-server-second-demo",
      "server_name": "Currency Converter MCP",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@Kermetek473/aaaaaa",
      "server_name": "AAAAAA MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@jessebautista/mcp-openproject-smithery",
      "server_name": "OpenProject Integration Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@jwalsh/mcp-server-qrcode",
      "server_name": "QR Code Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@IlaydaBayrak/soz-mcp",
      "server_name": "Soz MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@himanshusanecha/mcp-osint-server",
      "server_name": "OSINT Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@pandaow3r/mcp_server_test",
      "server_name": "Python MCP Server Template",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@NexusX-MCP/x-v2-server",
      "server_name": "X V2 MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@JackKuo666/pypi-mcp-server",
      "server_name": "PyPI MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@HenkDz/selfhosted-supabase-mcp",
      "server_name": "Self-Hosted Supabase MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@alperenkocyigit/weather-forecast-mcp",
      "server_name": "Weather Forecast Service",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@JackKuo666/sci-hub-mcp-server",
      "server_name": "Sci-Hub MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "mcp-obsidian",
      "server_name": "Obsidian Reader",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@JackKuo666/google-scholar-mcp-server",
      "server_name": "Google Scholar MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@JackKuo666/biorxiv-mcp-server",
      "server_name": "bioRxiv MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@yurthankiyak/weather-forecast55",
      "server_name": "Weather Forecast Service",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@mendableai/mcp-server-firecrawl",
      "server_name": "FireCrawl",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@Hans-M-Yin/jimeng-mcp",
      "server_name": "Jimeng AI Image Generation Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@crystaldba/postgres-mcp",
      "server_name": "Postgres MCP Pro",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@zehranurugurr/film_mcp_v2",
      "server_name": "Film Information Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@block/code-mcp",
      "server_name": "Code MCP",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@JackKuo666/crossref-mcp-server",
      "server_name": "Crossref MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@DynamicEndpoints/m365-core-mcp",
      "server_name": "Microsoft 365 Core Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@HarunGuclu/mcp_quran",
      "server_name": "Quran MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@automatalabs/mcp-server-playwright",
      "server_name": "Playwright",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@FutureAtoms/agentic-control-framework",
      "server_name": "Agentic Control Framework",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@williamvd4/playwright-plus-python-mcp",
      "server_name": "Playwright Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@CaullenOmdahl/pexels-mcp-server",
      "server_name": "Pexels MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@quintusr/supreme-broccoli",
      "server_name": "Supreme Broccoli",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "mcp_snowflake_server",
      "server_name": "Snowflake Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@SecurFi/rapidapi_mcp",
      "server_name": "RapidAPI",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@llmindset/mcp-miro",
      "server_name": "MIRO Whiteboard Connector",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@BitlyExchange/exchange",
      "server_name": "Bitly Exchange MCP Server",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@Alex2Yang97/yahoo-finance-mcp",
      "server_name": "Yahoo Finance Integration",
      "reason": "zero_valid_tools"
    },
    {
      "server_id": "@abhiz123/todoist-mcp-server",
      "server_name": "Todoist MCP Server",
      "reason": "zero_valid_tools"
    }
  ]
}